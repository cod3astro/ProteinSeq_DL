{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754ebf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Combining FASTA files with metadata tracking...\n",
      "  Reading Bacteria from bacteria_uniref.fasta...\n",
      "    Added 243,465 sequences from Bacteria\n",
      "  Reading Archaea from archaea_uniref.fasta...\n",
      "    Added 815,399 sequences from Archaea\n",
      "  Reading Plants from plants_uniref.fasta...\n",
      "    Added 826,491 sequences from Plants\n",
      "  Reading Mammals from mammals_uniref.fasta...\n",
      "    Added 910,034 sequences from Mammals\n",
      "  Reading Fungi from fungi_uniref.fasta...\n",
      "    Added 985,183 sequences from Fungi\n",
      "  Reading Arthropods from arthropods_uniref.fasta...\n",
      "    Added 1,880,722 sequences from Arthropods\n",
      "  Shuffling sequences...\n",
      "\n",
      "âœ… Successfully combined 5,661,294 sequences\n",
      "ğŸ“ Combined FASTA saved to: c:\\Users\\USER\\Documents\\cod3astro\\ML_AI\\ProteinSeq_DL\\data\\processed\\combined_pretrain.fasta\n",
      "ğŸ“Š Metadata saved to: c:\\Users\\USER\\Documents\\cod3astro\\ML_AI\\ProteinSeq_DL\\data\\processed\\pretrain_metadata.csv\n",
      "\n",
      "ğŸ“ˆ Dataset Statistics:\n",
      "Total sequences: 5,661,294\n",
      "Files combined: 6\n",
      "\n",
      "ğŸ“Š Distribution by organism:\n",
      "source_organism\n",
      "Arthropods    1880722\n",
      "Fungi          985183\n",
      "Mammals        910034\n",
      "Plants         826491\n",
      "Archaea        815399\n",
      "Bacteria       243465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ“ Sequence length statistics:\n",
      "Min length: 50\n",
      "Max length: 1000\n",
      "Average length: 174.4\n",
      "\n",
      "ğŸ’¾ File sizes:\n",
      "Combined FASTA: 1.05 GB\n",
      "Metadata CSV: 809.78 MB\n",
      "\n",
      "ğŸ‘€ Sample entries (first 3):\n",
      "              sequence_id           source_file source_organism  sequence_length                                                                                                 sequence\n",
      "0  UniRef90_UPI002019110D  mammals_uniref.fasta         Mammals              323  MAPKQDPKPKFQEGERVLCFHGPLLYEAKCVKVAVKDKQVKYFIHYSGWNKNWDEWVSESRVLKHVEGNLQKQRELQKANQEQCAEGKMRGAAPGKKTSG...\n",
      "1     UniRef90_A0ABX0SAI2  mammals_uniref.fasta         Mammals              204  MVQARPGARPTLLPGPSTAWVSGFSGGGSDLTGAREAQERARWSPTESSSASVSPVAKVSKFTLSSELEARDYPKERGRTSRGLGRPPDWEPCAAEVPAE...\n",
      "2     UniRef50_A0A816IN08   plants_uniref.fasta          Plants              277  VQKIAEYIDEEDLFKRFNDPVRAAFDIFEEEEEEVNDCQSTTTKRRRMSSEEEIINSNKKILRTCNHYEGQCQDNFNQLLCMQPHHINQPNQMGFVSNLL...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent  \n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "PRETRAIN_DATA_DIR = project_root / \"data\" / \"raw\" / \"pretrain\"\n",
    "TRAIN_DATA_DIR = project_root / \"data\" / \"raw\" / \"train\"\n",
    "PROCESSED_DIR = project_root / \"data\" / \"processed\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pretrain_fasta_files = [\n",
    "    PRETRAIN_DATA_DIR / \"bacteria_uniref.fasta\",\n",
    "    PRETRAIN_DATA_DIR / \"archaea_uniref.fasta\",\n",
    "    PRETRAIN_DATA_DIR / \"plants_uniref.fasta\",\n",
    "    PRETRAIN_DATA_DIR / \"mammals_uniref.fasta\",\n",
    "    PRETRAIN_DATA_DIR / \"fungi_uniref.fasta\",\n",
    "    PRETRAIN_DATA_DIR / \"arthropods_uniref.fasta\"\n",
    "]\n",
    "\n",
    "def combine_fasta_files_with_metadata(fasta_files, output_fasta, output_metadata):\n",
    "    \"\"\"Combine FASTA files and create metadata tracking file\"\"\"\n",
    "    print(\"Step 1: Combining FASTA files with metadata tracking...\")\n",
    "    \n",
    "    combined_sequences = []  \n",
    "    metadata_records = []    \n",
    "    \n",
    "    for fasta_file in fasta_files:\n",
    "        if fasta_file.exists():  \n",
    "            source_name = fasta_file.stem.replace(\"_uniref\", \"\").replace(\"_\", \" \").title()\n",
    "            print(f\"  Reading {source_name} from {fasta_file.name}...\")\n",
    "            \n",
    "            count = 0  \n",
    "            \n",
    "            # SeqIO.parse reads FASTA files one record at a time\n",
    "            for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "                \n",
    "                # 1. Store sequence in FASTA format\n",
    "                combined_sequences.append(f\">{record.id}\\n{str(record.seq)}\")\n",
    "                \n",
    "                # 2. Store metadata\n",
    "                metadata_records.append({\n",
    "                    'sequence_id': record.id,  # Protein ID\n",
    "                    'source_file': fasta_file.name,  # Which file it came from\n",
    "                    'source_organism': source_name,  # Organism group\n",
    "                    'sequence_length': len(record.seq),  # Length of protein\n",
    "                    'sequence': str(record.seq)[:100] + \"...\" if len(record.seq) > 100 else str(record.seq)\n",
    "                    # Store first 100 characters (for verification)\n",
    "                })\n",
    "                count += 1  \n",
    "            \n",
    "            print(f\"    Added {count:,} sequences from {source_name}\")\n",
    "    \n",
    "    print(\"  Shuffling sequences...\")\n",
    "    # Combine sequences and metadata into pairs\n",
    "    combined = list(zip(combined_sequences, metadata_records))\n",
    "    random.shuffle(combined)  # Randomly shuffle the pairs\n",
    "    # Split them back into separate lists\n",
    "    combined_sequences, metadata_records = zip(*combined)\n",
    "    \n",
    "    with open(output_fasta, \"w\") as f:\n",
    "        # Join all FASTA entries with newlines and write to file\n",
    "        f.write(\"\\n\".join(combined_sequences))\n",
    "    \n",
    "    import pandas as pd  \n",
    "    df_metadata = pd.DataFrame(metadata_records)  # Convert list of dicts to DataFrame\n",
    "    df_metadata.to_csv(output_metadata, index=False)  # Save as CSV\n",
    "    \n",
    "    print(f\"\\nâœ… Successfully combined {len(combined_sequences):,} sequences\")\n",
    "    print(f\"ğŸ“ Combined FASTA saved to: {output_fasta}\")\n",
    "    print(f\"ğŸ“Š Metadata saved to: {output_metadata}\")\n",
    "    \n",
    "    return len(combined_sequences), output_fasta, output_metadata\n",
    "\n",
    "# Define output file paths\n",
    "combined_pretrain_fasta = PROCESSED_DIR / \"combined_pretrain.fasta\"\n",
    "combined_pretrain_metadata = PROCESSED_DIR / \"pretrain_metadata.csv\"\n",
    "\n",
    "# Call the function and capture the return values\n",
    "sequence_count, combined_file, metadata_file = combine_fasta_files_with_metadata(\n",
    "    pretrain_fasta_files,\n",
    "    combined_pretrain_fasta,\n",
    "    combined_pretrain_metadata\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“ˆ Dataset Statistics:\")\n",
    "print(f\"Total sequences: {sequence_count:,}\")  # Use the returned count\n",
    "print(f\"Files combined: {len([f for f in pretrain_fasta_files if f.exists()])}\")\n",
    "\n",
    "# Check organism distribution (need to read the metadata CSV)\n",
    "import pandas as pd  # Import pandas if not already imported\n",
    "df_meta = pd.read_csv(metadata_file)  # Read the metadata CSV we just created\n",
    "\n",
    "print(\"\\nğŸ“Š Distribution by organism:\")\n",
    "print(df_meta['source_organism'].value_counts())\n",
    "\n",
    "# Length statistics\n",
    "print(f\"\\nğŸ“ Sequence length statistics:\")\n",
    "print(f\"Min length: {df_meta['sequence_length'].min()}\")\n",
    "print(f\"Max length: {df_meta['sequence_length'].max()}\")\n",
    "print(f\"Average length: {df_meta['sequence_length'].mean():.1f}\")\n",
    "\n",
    "# Show file sizes\n",
    "import os\n",
    "print(f\"\\nğŸ’¾ File sizes:\")\n",
    "print(f\"Combined FASTA: {os.path.getsize(combined_file) / (1024**3):.2f} GB\")\n",
    "print(f\"Metadata CSV: {os.path.getsize(metadata_file) / (1024**2):.2f} MB\")\n",
    "\n",
    "# Show sample of the data\n",
    "print(f\"\\nğŸ‘€ Sample entries (first 3):\")\n",
    "print(df_meta.head(3).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
