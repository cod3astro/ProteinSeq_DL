{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49391d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial - Memory Usage: 0.29 GB\n",
      "\n",
      "STARTING PROTEIN GO TERM PROCESSING\n",
      "Start Time: 07:43:56\n",
      "Initial Memory: 0.29 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEXPLANATION OF SECTION 5:\\n\\n1. initial_mem = print_memory_usage(\"Initial\")\\n   - Captures memory before processing begins.\\n   - Later we can compare:\\n         current_memory - initial_memory\\n   - Helps detect memory leaks.\\n\\n2. time.strftime(\\'%H:%M:%S\\')\\n   - Formats current time as Hour:Minute:Second.\\n\\n3. Logging statements\\n   - Useful for reproducibility.\\n   - Important when running experiments overnight or on servers.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from collections import Counter\n",
    "import gc\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "1. pandas (pd)\n",
    "   - Used for structured/tabular data manipulation.\n",
    "   - Likely used later for reading protein datasets (e.g., CSV with sequences and GO terms).\n",
    "   - Provides functions like:\n",
    "       - read_csv(), sort_values(), unique(), groupby(), reset_index()\n",
    "\n",
    "2. numpy (np)\n",
    "   - Used for numerical operations.\n",
    "   - Deep learning models require numerical arrays.\n",
    "   - Useful for:\n",
    "       - vector operations, encoding labels, reshaping data\n",
    "\n",
    "3. Dataset (from HuggingFace datasets library)\n",
    "   - Converts data into an optimized format for training.\n",
    "   - Often used with transformers or large NLP models.\n",
    "   - If not using HuggingFace Trainer or tokenizers later, this import may be unnecessary.\n",
    "\n",
    "4. Counter\n",
    "   - Counts frequency of elements in a list.\n",
    "   - Very useful for:\n",
    "       - Counting GO term frequencies, Detecting class imbalance\n",
    "\n",
    "5. gc (Garbage Collector)\n",
    "   - Frees memory manually using gc.collect()\n",
    "   - Important when handling large biological datasets.\n",
    "\n",
    "\n",
    "6. time\n",
    "   - Used to measure execution time.\n",
    "\n",
    "7. psutil\n",
    "   - Tracks memory usage of current process.\n",
    "   - Useful for monitoring RAM consumption.\n",
    "\n",
    "8. os\n",
    "   - Used for operating system utilities.\n",
    "   - Here it is used to get current process ID.\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. time.time()\n",
    "   - Returns current time in seconds since epoch.\n",
    "   - Used to calculate total runtime later: total_time = time.time() - start_time\n",
    "\n",
    "2. os.getpid()\n",
    "   - Gets the process ID of the current Python program.\n",
    "\n",
    "3. psutil.Process(pid)\n",
    "   - Attaches a memory-monitoring object to this process.\n",
    "   - Allows access to:\n",
    "       - memory usage, CPU usage, other process stats\n",
    "\"\"\"\n",
    "\n",
    "def print_memory_usage(step_name):\n",
    "    mem_info = process.memory_info()\n",
    "    mem_gb = mem_info.rss / (1024 ** 3)\n",
    "\n",
    "    print(f\"{step_name} - Memory Usage: {mem_gb:.2f} GB\")\n",
    "    return mem_gb\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "Function Purpose:\n",
    "This function checks how much RAM the program is currently using.\n",
    "\n",
    "Line-by-line explanation:\n",
    "\n",
    "1. process.memory_info()\n",
    "   - Retrieves memory statistics for current process.\n",
    "   - Returns an object containing:\n",
    "       - rss (Resident Set Size)\n",
    "       - vms (Virtual memory size)\n",
    "\n",
    "2. mem_info.rss\n",
    "   - RSS = actual physical memory being used.\n",
    "   - This is the most relevant measure for memory usage.\n",
    "\n",
    "3. (1024 ** 3)\n",
    "   - Converts bytes to gigabytes.\n",
    "\n",
    "4. print(f\"{step_name} - Memory Usage: {mem_gb:.2f} GB\")\n",
    "   - Displays step name AND memory.\n",
    "   - This fixes earlier version where step_name was unused.\n",
    "\n",
    "SIMPLIFICATION:\n",
    "Original function accepted step_name but did not use it.\n",
    "This version properly integrates it.\n",
    "Function behavior remains identical.\n",
    "\"\"\"\n",
    "\n",
    "def print_step_header(step_num, step_name):\n",
    "    separator = \"=\" * 60\n",
    "\n",
    "    print(\"\\n\" + separator)\n",
    "    print(f\"STEP {step_num}: {step_name}\")\n",
    "    print(separator)\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "Purpose:\n",
    "This function improves readability when running long pipelines.\n",
    "\n",
    "1. \"=\" * 60\n",
    "   - Repeats \"=\" 60 times.\n",
    "   - Creates a clear visual separator.\n",
    "\n",
    "2. print(\"\\n\" + separator)\n",
    "   - Adds spacing before new step.\n",
    "\n",
    "3. f\"STEP {step_num}: {step_name}\"\n",
    "   - Displays structured step numbering.\n",
    "\n",
    "Why this is useful:\n",
    "When processing protein datasets, multiple stages exist:\n",
    "    - Loading data, Cleaning, Encoding, Training, Evaluation\n",
    "\n",
    "This prevents confusion during long runs.\n",
    "\n",
    "SIMPLIFICATION:\n",
    "Original implementation was already clean.\n",
    "We just stored separator in a variable for clarity.\n",
    "Function output remains identical.\n",
    "\"\"\"\n",
    "\n",
    "initial_mem = print_memory_usage(\"Initial\")\n",
    "\n",
    "print(\"\\nSTARTING PROTEIN GO TERM PROCESSING\")\n",
    "print(f\"Start Time: {time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Initial Memory: {initial_mem:.2f} GB\")\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. initial_mem = print_memory_usage(\"Initial\")\n",
    "   - Captures memory before processing begins.\n",
    "   - Later we can compare:\n",
    "         current_memory - initial_memory\n",
    "   - Helps detect memory leaks.\n",
    "\n",
    "2. time.strftime('%H:%M:%S')\n",
    "   - Formats current time as Hour:Minute:Second.\n",
    "\n",
    "3. Logging statements\n",
    "   - Useful for reproducibility.\n",
    "   - Important when running experiments overnight or on servers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d149e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV entries: 105951\n",
      "FASTA sequences: 105951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nEXPLANATION OF SECTION 4:\\n\\n1. len(labels_df)\\n   - Returns number of rows in DataFrame.\\n   - Equivalent to number of labeled proteins.\\n\\n2. len(sequence_dict)\\n   - Returns number of protein sequences parsed.\\n\\nWhy this is important:\\nWe must verify that:\\n    number of labels ≈ number of sequences\\n\\nIf they differ significantly:\\n    - Some proteins may lack sequences\\n    - Some sequences may lack labels\\n    - IDs may not match\\n\\nLater, we must ensure proper merging.\\n\\nIMPORTANT NEXT STEP (very important for deep learning):\\n\\nWe must check:\\n    set(labels_df['protein_id_column']) \\n        ∩ \\n    set(sequence_dict.keys())\\n\\nIf intersection is smaller than expected, we may silently lose data.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "Bio.SeqIO is a module from the Biopython library used for reading\n",
    "biological sequence files such as FASTA, GenBank, etc.\n",
    "\n",
    "SeqIO can:\n",
    "- Parse FASTA files automatically\n",
    "- Extract IDs and sequences cleanly\n",
    "- Avoid manual string parsing\n",
    "\"\"\"\n",
    "\n",
    "tsv_path = \"C:/Users/USER/Documents/cod3astro/ML_AI/ProteinSeq_DL/data/raw/train/uniprotkb_AND_reviewed_true_AND_protein_2025_12_27.tsv\"\n",
    "labels_df = pd.read_csv(tsv_path, sep='\\t')\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. pd.read_csv(tsv_path, sep='\\t')\n",
    "\n",
    "   - read_csv() loads tabular data into a pandas DataFrame.\n",
    "   - sep='\\t' tells pandas that the file is TAB-separated.\n",
    "   - TSV = Tab Separated Values.\n",
    "\n",
    "The result:\n",
    "labels_df is a DataFrame (rows × columns).\n",
    "This DataFrame will later be merged with sequences.\n",
    "\"\"\"\n",
    "\n",
    "fasta_path = \"C:/Users/USER/Documents/cod3astro/ML_AI/ProteinSeq_DL/data/raw/train/uniprotkb_AND_reviewed_true_AND_protein_2025_12_27.fasta\"\n",
    "sequence_dict = {}\n",
    "\n",
    "for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "    # UniProt FASTA headers look like:\n",
    "    # sp|P12345|PROTEIN_NAME\n",
    "    # We extract the middle ID (P12345)\n",
    "\n",
    "    header = record.id\n",
    "    if \"|\" in header:\n",
    "        protein_id = header.split(\"|\")[1]\n",
    "    else:\n",
    "        protein_id = header.split()[0]\n",
    "    sequence_dict[protein_id] = str(record.seq)\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. SeqIO.parse(fasta_path, \"fasta\")\n",
    "\n",
    "   - Reads FASTA file safely.\n",
    "   - Automatically handles:\n",
    "        - Multi-line sequences\n",
    "        - Header parsing\n",
    "        - End-of-file cases\n",
    "\n",
    "2. record.id\n",
    "   - Returns FASTA header identifier.\n",
    "   - Example:\n",
    "        sp|P12345|PROTEIN_NAME\n",
    "\n",
    "3. header.split(\"|\")[1]\n",
    "   - Splits string at \"|\".\n",
    "   - Index 1 extracts middle ID (P12345).\n",
    "   - This matches the original logic.\n",
    "\n",
    "4. sequence_dict[protein_id] = str(record.seq)\n",
    "   - record.seq is a Seq object.\n",
    "   - Convert to string for easier handling later.\n",
    "\n",
    "Result:\n",
    "sequence_dict:\n",
    "    {\n",
    "        \"P12345\": \"MTEYKLVVVGAGGVGKS...\",\n",
    "        ...\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "print(f\"TSV entries: {len(labels_df)}\")\n",
    "print(f\"FASTA sequences: {len(sequence_dict)}\")\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. len(labels_df)\n",
    "   - Returns number of rows in DataFrame.\n",
    "   - Equivalent to number of labeled proteins.\n",
    "\n",
    "2. len(sequence_dict)\n",
    "   - Returns number of protein sequences parsed.\n",
    "\n",
    "Why this is important:\n",
    "We must verify that:\n",
    "    number of labels ≈ number of sequences\n",
    "\n",
    "If they differ significantly:\n",
    "    - Some proteins may lack sequences\n",
    "    - Some sequences may lack labels\n",
    "    - IDs may not match\n",
    "\n",
    "Later, we must ensure proper merging.\n",
    "\n",
    "IMPORTANT NEXT STEP (very important for deep learning):\n",
    "\n",
    "We must check:\n",
    "    set(labels_df['protein_id_column']) \n",
    "        ∩ \n",
    "    set(sequence_dict.keys())\n",
    "\n",
    "If intersection is smaller than expected, we may silently lose data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebc940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIMPORTANT:\\n\\nBecause each protein can have MULTIPLE GO terms,\\nthe task is:\\n    MULTI-LABEL CLASSIFICATION\\n\\nThis changes everything downstream:\\n\\n1. We CANNOT use:\\n       CrossEntropyLoss\\n   Because that assumes ONE label per sample.\\n\\n2. We MUST use:\\n       BCEWithLogitsLoss (if PyTorch)\\n   or\\n       BinaryCrossentropy (if Keras)\\n\\n3. The output layer must be:\\n       number_of_unique_GO_terms neurons\\n\\n4. Final activation should be:\\n       Sigmoid (not Softmax)\\n\\nSoftmax = probabilities sum to 1 (single-label)\\nSigmoid = independent probabilities per class (multi-label)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_go_terms(go_string):\n",
    "    \"\"\"\n",
    "    Convert a semicolon-separated GO string into a Python list.\n",
    "\n",
    "    Example:\n",
    "        Input  → \"GO:0008150;GO:0003674\"\n",
    "        Output → [\"GO:0008150\", \"GO:0003674\"]\n",
    "\n",
    "    This is required because:\n",
    "    - The dataset stores multiple GO annotations in one cell.\n",
    "    - Deep learning models cannot work with raw strings.\n",
    "    - We must convert them into structured format (list).\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(go_string) or go_string == \"\":\n",
    "        return []\n",
    "\n",
    "    \"\"\"\n",
    "    EXPLANATION:\n",
    "\n",
    "    1. pd.isna(go_string)\n",
    "       - Checks whether value is NaN (missing).\n",
    "       - NaN can appear if a protein has no GO annotations.\n",
    "\n",
    "    2. go_string == \"\"\n",
    "       - Handles empty strings.\n",
    "       - Sometimes TSV files store missing values as \"\" instead of NaN.\n",
    "\n",
    "    Why return [] instead of None?\n",
    "       - Returning an empty list keeps data type consistent.\n",
    "       - Later, we will expect a LIST of GO terms.\n",
    "       - Returning None would break later loops.\n",
    "\n",
    "    Deep learning perspective:\n",
    "       If we are doing multi-label classification,\n",
    "       returning [] means this protein has no labels.\n",
    "       We must later decide:\n",
    "           - Remove such proteins or Keep them?\n",
    "    \"\"\"\n",
    "\n",
    "    return [term.strip() for term in str(go_string).split(';')]\n",
    "\n",
    "    \"\"\"\n",
    "    EXPLANATION:\n",
    "\n",
    "    1. str(go_string)\n",
    "       - Ensures the value is treated as string.\n",
    "       - Defensive programming in case data type is unexpected.\n",
    "\n",
    "    2. .split(';')\n",
    "       - Splits string at each semicolon.\n",
    "       - Example:\n",
    "           \"GO:0003953; GO:0007165\"\n",
    "       becomes:\n",
    "           [\"GO:0003953\", \" GO:0007165\"]\n",
    "\n",
    "    3. term.strip()\n",
    "       - Removes leading/trailing whitespace.\n",
    "       - Important because some entries have space after semicolon.\n",
    "       - Example: \" GO:0007165\" → \"GO:0007165\"\n",
    "\n",
    "    4. List comprehension\n",
    "       - Efficient way to apply transformation to each term.\n",
    "       - Cleaner than using a for-loop.\n",
    "\n",
    "    FINAL RESULT: A Python list of GO term strings.\n",
    "\n",
    "    IMPORTANT CONCEPTUAL NOTE:\n",
    "        We are converting from:\n",
    "            Multi-label string format\n",
    "        into:\n",
    "            Structured multi-label list format.\n",
    "\n",
    "        This means the problem is NOT single-class classification, It is multi-label classification.\n",
    "    \"\"\"\n",
    "\n",
    "labels_df['go_terms_list'] = labels_df['Gene Ontology IDs'].apply(parse_go_terms)\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. labels_df['Gene Ontology IDs']\n",
    "   - Selects the column containing raw GO strings.\n",
    "\n",
    "2. .apply(parse_go_terms)\n",
    "   - Applies the function to EACH row.\n",
    "   - Equivalent to:\n",
    "         for each row:\n",
    "             parse_go_terms(value)\n",
    "   But much cleaner and vectorized.\n",
    "\n",
    "3. labels_df['go_terms_list'] = ...\n",
    "   - Creates a NEW column.\n",
    "   - Does not overwrite original data.\n",
    "   - Good practice for traceability.\n",
    "\n",
    "Now your DataFrame contains:\n",
    "\n",
    "Column: 'Gene Ontology IDs'\n",
    "    → Raw string format\n",
    "\n",
    "Column: 'go_terms_list'\n",
    "    → Python list format\n",
    "\n",
    "Example:\n",
    "\n",
    "Before:\n",
    "    \"GO:0003953; GO:0007165\"\n",
    "After:\n",
    "    [\"GO:0003953\", \"GO:0007165\"]\n",
    "\n",
    "This structured list is REQUIRED for:\n",
    "    - Counting frequencies (Counter), Building label vocabulary, Multi-hot encoding, Training neural networks\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANT:\n",
    "\n",
    "Because each protein can have MULTIPLE GO terms,\n",
    "the task is:\n",
    "    MULTI-LABEL CLASSIFICATION\n",
    "\n",
    "This changes everything downstream:\n",
    "\n",
    "1. We CANNOT use:\n",
    "       CrossEntropyLoss\n",
    "   Because that assumes ONE label per sample.\n",
    "\n",
    "2. We MUST use:\n",
    "       BCEWithLogitsLoss (if PyTorch)\n",
    "   or\n",
    "       BinaryCrossentropy (if Keras)\n",
    "\n",
    "3. The output layer must be:\n",
    "       number_of_unique_GO_terms neurons\n",
    "\n",
    "4. Final activation should be:\n",
    "       Sigmoid (not Softmax)\n",
    "\n",
    "Softmax = probabilities sum to 1 (single-label)\n",
    "Sigmoid = independent probabilities per class (multi-label)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3810254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology IDs</th>\n",
       "      <th>go_terms_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>ABTIR_ACIB9</td>\n",
       "      <td>2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...</td>\n",
       "      <td>Acinetobacter baumannii (strain 1295743)</td>\n",
       "      <td>MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...</td>\n",
       "      <td>GO:0003953; GO:0007165; GO:0019677; GO:0050135...</td>\n",
       "      <td>[GO:0003953, GO:0007165, GO:0019677, GO:005013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023I7E1</td>\n",
       "      <td>ENG1_RHIMI</td>\n",
       "      <td>Glucan endo-1,3-beta-D-glucosidase 1 (Endo-1,3...</td>\n",
       "      <td>Rhizomucor miehei</td>\n",
       "      <td>MRFQVIVAAATITMITSYIPGVASQSTSDGDDLFVPVSNFDPKSIF...</td>\n",
       "      <td>GO:0000272; GO:0005576; GO:0042973; GO:0052861...</td>\n",
       "      <td>[GO:0000272, GO:0005576, GO:0042973, GO:005286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A024B7W1</td>\n",
       "      <td>POLG_ZIKVF</td>\n",
       "      <td>Genome polyprotein [Cleaved into: Capsid prote...</td>\n",
       "      <td>Zika virus (isolate ZIKV/Human/French Polynesi...</td>\n",
       "      <td>MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRM...</td>\n",
       "      <td>GO:0003724; GO:0003725; GO:0003968; GO:0004252...</td>\n",
       "      <td>[GO:0003724, GO:0003725, GO:0003968, GO:000425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A024RXP8</td>\n",
       "      <td>GUX1_HYPJR</td>\n",
       "      <td>Exoglucanase 1 (EC 3.2.1.91) (1,4-beta-cellobi...</td>\n",
       "      <td>Hypocrea jecorina (strain ATCC 56765 / BCRC 32...</td>\n",
       "      <td>MYRKLAVISAFLATARAQSACTLQSETHPPLTWQKCSSGGTCTQQT...</td>\n",
       "      <td>GO:0005576; GO:0016162; GO:0030245; GO:0030248</td>\n",
       "      <td>[GO:0005576, GO:0016162, GO:0030245, GO:0030248]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A024SC78</td>\n",
       "      <td>CUTI1_HYPJR</td>\n",
       "      <td>Cutinase (EC 3.1.1.74)</td>\n",
       "      <td>Hypocrea jecorina (strain ATCC 56765 / BCRC 32...</td>\n",
       "      <td>MRSLAILTTLLAGHAFAYPKPAPQSVNRRDWPSINEFLSELAKVMP...</td>\n",
       "      <td>GO:0005576; GO:0016052; GO:0050525</td>\n",
       "      <td>[GO:0005576, GO:0016052, GO:0050525]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry   Entry Name                                      Protein names  \\\n",
       "0  A0A009IHW8  ABTIR_ACIB9  2' cyclic ADP-D-ribose synthase AbTIR (2'cADPR...   \n",
       "1  A0A023I7E1   ENG1_RHIMI  Glucan endo-1,3-beta-D-glucosidase 1 (Endo-1,3...   \n",
       "2  A0A024B7W1   POLG_ZIKVF  Genome polyprotein [Cleaved into: Capsid prote...   \n",
       "3  A0A024RXP8   GUX1_HYPJR  Exoglucanase 1 (EC 3.2.1.91) (1,4-beta-cellobi...   \n",
       "4  A0A024SC78  CUTI1_HYPJR                             Cutinase (EC 3.1.1.74)   \n",
       "\n",
       "                                            Organism  \\\n",
       "0           Acinetobacter baumannii (strain 1295743)   \n",
       "1                                  Rhizomucor miehei   \n",
       "2  Zika virus (isolate ZIKV/Human/French Polynesi...   \n",
       "3  Hypocrea jecorina (strain ATCC 56765 / BCRC 32...   \n",
       "4  Hypocrea jecorina (strain ATCC 56765 / BCRC 32...   \n",
       "\n",
       "                                            Sequence  \\\n",
       "0  MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...   \n",
       "1  MRFQVIVAAATITMITSYIPGVASQSTSDGDDLFVPVSNFDPKSIF...   \n",
       "2  MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRM...   \n",
       "3  MYRKLAVISAFLATARAQSACTLQSETHPPLTWQKCSSGGTCTQQT...   \n",
       "4  MRSLAILTTLLAGHAFAYPKPAPQSVNRRDWPSINEFLSELAKVMP...   \n",
       "\n",
       "                                   Gene Ontology IDs  \\\n",
       "0  GO:0003953; GO:0007165; GO:0019677; GO:0050135...   \n",
       "1  GO:0000272; GO:0005576; GO:0042973; GO:0052861...   \n",
       "2  GO:0003724; GO:0003725; GO:0003968; GO:0004252...   \n",
       "3     GO:0005576; GO:0016162; GO:0030245; GO:0030248   \n",
       "4                 GO:0005576; GO:0016052; GO:0050525   \n",
       "\n",
       "                                       go_terms_list  \n",
       "0  [GO:0003953, GO:0007165, GO:0019677, GO:005013...  \n",
       "1  [GO:0000272, GO:0005576, GO:0042973, GO:005286...  \n",
       "2  [GO:0003724, GO:0003725, GO:0003968, GO:000425...  \n",
       "3   [GO:0005576, GO:0016162, GO:0030245, GO:0030248]  \n",
       "4               [GO:0005576, GO:0016052, GO:0050525]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134b21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched proteins: 105951\n",
      "Saved to: C:/Users/USER/Documents/cod3astro/ML_AI/ProteinSeq_DL/data/processed/training_data_combined.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEXPLANATION:\\n\\n1. to_csv(output_path, index=False)\\n\\n   - Saves processed dataset to disk.\\n   - index=False prevents saving row indices.\\n   - Ensures clean, reusable CSV file.\\n\\nWhy this step is important:\\n\\n- FASTA parsing is computationally expensive.\\n- Merging datasets repeatedly wastes time.\\n- Saving intermediate dataset improves reproducibility.\\n- This file becomes the starting point for:\\n        tokenization\\n        label encoding\\n        model training\\n\\nThis concludes construction of the unified training dataset.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = labels_df[labels_df['Entry'].isin(sequence_dict.keys())].copy()\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "In this section, we perform a vectorized matching operation between:\n",
    "\n",
    "    - Protein accession IDs from the label DataFrame\n",
    "    - Keys of sequence_dict (which contain available FASTA sequences)\n",
    "\n",
    "Step-by-step explanation:\n",
    "\n",
    "1. labels_df['Entry']\n",
    "   - This selects the column containing UniProt accession IDs.\n",
    "   - Each value represents one protein.\n",
    "\n",
    "2. .isin(sequence_dict.keys())\n",
    "   - The isin() function checks whether each element of the column\n",
    "     exists inside a given collection.\n",
    "   - Here, the collection is sequence_dict.keys(), which contains\n",
    "     all protein IDs parsed from the FASTA file.\n",
    "\n",
    "   Conceptually, this creates a Boolean mask:\n",
    "        True  → accession exists in sequence_dict\n",
    "        False → accession does not exist\n",
    "\n",
    "3. labels_df[ ... ]\n",
    "   - We use this Boolean mask to filter rows.\n",
    "   - This keeps only proteins that have corresponding sequences.\n",
    "\n",
    "4. .copy()\n",
    "   - Creates a deep copy of the filtered data.\n",
    "   - This prevents SettingWithCopyWarning later.\n",
    "   - It ensures modifications do not affect the original DataFrame.\n",
    "\n",
    "Conceptual interpretation:\n",
    "\n",
    "This operation is equivalent to performing an INNER JOIN between:\n",
    "    labels_df (TSV data)\n",
    "and\n",
    "    sequence_dict (FASTA data)\n",
    "\n",
    "However, instead of looping row-by-row, we use pandas' vectorized operations, which are significantly faster and more memory-efficient.\n",
    "\"\"\"\n",
    "\n",
    "filtered_df['sequence'] = filtered_df['Entry'].map(sequence_dict)\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "Now that we have filtered proteins that exist in sequence_dict, we attach their sequences directly into the DataFrame.\n",
    "\n",
    "1. .map(sequence_dict)\n",
    "\n",
    "   - The map() function replaces each value in a Series\n",
    "     using a dictionary lookup.\n",
    "   - For each accession ID in filtered_df['Entry']:\n",
    "         sequence_dict[accession] is retrieved.\n",
    "\n",
    "   Example:\n",
    "        If accession = \"A0A009IHW8\"\n",
    "        Then:\n",
    "            sequence_dict[\"A0A009IHW8\"] → \"MSLEQKKGADIISKIL...\"\n",
    "\n",
    "2. filtered_df['sequence'] = ...\n",
    "   - Creates a new column called 'sequence'\n",
    "   - Each row now contains:\n",
    "         accession\n",
    "         original metadata\n",
    "         parsed GO term list\n",
    "         full amino acid sequence\n",
    "\n",
    "Why this is efficient:\n",
    "\n",
    "- Dictionary lookup is O(1) on average.\n",
    "- No explicit Python loops.\n",
    "- Fully vectorized within pandas.\n",
    "\"\"\"\n",
    "\n",
    "train_df = filtered_df[['Entry', 'sequence', 'go_terms_list', 'Organism']].rename(\n",
    "    columns={\n",
    "        'Entry': 'accession',\n",
    "        'go_terms_list': 'go_terms',\n",
    "        'Organism': 'organism'\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "In this section, we reduce the DataFrame to only essential columns\n",
    "required for model training.\n",
    "\n",
    "1. filtered_df[['Entry', 'sequence', 'go_terms_list', 'Organism']]\n",
    "\n",
    "   - Selects only necessary columns.\n",
    "   - Removes irrelevant metadata (protein names, etc.).\n",
    "   - This reduces memory usage and improves clarity.\n",
    "\n",
    "2. .rename(columns={...})\n",
    "\n",
    "   - Renames columns to cleaner, standardized names.\n",
    "   - 'Entry' → 'accession'\n",
    "   - 'go_terms_list' → 'go_terms'\n",
    "   - 'Organism' → 'organism'\n",
    "\n",
    "Why renaming is important:\n",
    "\n",
    "- Improves readability\n",
    "- Makes downstream code cleaner\n",
    "- Avoids repeatedly referencing long column names\n",
    "\n",
    "After this step, train_df contains:\n",
    "   accession | sequence | go_terms | organism\n",
    "This becomes our core training dataset.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Matched proteins: {len(train_df)}\")\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. len(train_df)\n",
    "\n",
    "   - Returns number of successfully matched proteins.\n",
    "   - This equals the number of proteins that have:\n",
    "         ✔ GO annotations\n",
    "         ✔ Available amino acid sequence\n",
    "\n",
    "Sanity check:\n",
    "\n",
    "This number should be close to:\n",
    "        min(len(labels_df), len(sequence_dict))\n",
    "\n",
    "If it is significantly lower,\n",
    "this indicates ID mismatches between TSV and FASTA files.\n",
    "\n",
    "This step confirms integrity of data merging.\n",
    "\"\"\"\n",
    "\n",
    "output_path = \"C:/Users/USER/Documents/cod3astro/ML_AI/ProteinSeq_DL/data/processed/training_data_combined.csv\"\n",
    "train_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to: {output_path}\")\n",
    "\n",
    "\"\"\"\n",
    "EXPLANATION:\n",
    "\n",
    "1. to_csv(output_path, index=False)\n",
    "\n",
    "   - Saves processed dataset to disk.\n",
    "   - index=False prevents saving row indices.\n",
    "   - Ensures clean, reusable CSV file.\n",
    "\n",
    "Why this step is important:\n",
    "\n",
    "- FASTA parsing is computationally expensive.\n",
    "- Merging datasets repeatedly wastes time.\n",
    "- Saving intermediate dataset improves reproducibility.\n",
    "- This file becomes the starting point for:\n",
    "        tokenization\n",
    "        label encoding\n",
    "        model training\n",
    "\n",
    "This concludes construction of the unified training dataset.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
